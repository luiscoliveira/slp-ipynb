{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033d1dea",
   "metadata": {},
   "source": [
    "# Spoken Language Processing 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319cb7b",
   "metadata": {},
   "source": [
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26733ca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a5a0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e25299073f879702621a043e8379a890",
     "grade": false,
     "grade_id": "Title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Special Exam Project Part 1 - Speech Signal Processing\n",
    "\n",
    "This project assignment will introduce some tools and concepts for the manipulation and analysis of speech signals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247686cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c23745237ec3b76d112960d0c8dacf6f",
     "grade": false,
     "grade_id": "cell-a6c459a2e53d407c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8dfbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbaeb4aef065a013abe158dc70bc1536",
     "grade": false,
     "grade_id": "TeamID",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T1: Student identification\n",
    "\n",
    "Initialize the variables `student_name`, `student_id` with your name and student number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4577985",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1257df586a2798c446862c36ae6314a",
     "grade": false,
     "grade_id": "T1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(f\"Student: {student_name} ({student_id})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c5bc0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3aeba97c4877082427e34c95a2c678d",
     "grade": true,
     "grade_id": "T1t",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(student_id, int)\n",
    "assert isinstance(student_name, str)\n",
    "assert (student_id > 60000) and (student_id < 130000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b0ae8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63b3faf1a8effd67a1e8a2346a90efbb",
     "grade": false,
     "grade_id": "cell-d158bea835b3f398",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Python packages\n",
    "\n",
    "NumPy is a Python library that provides functions to process multidimensional array objects. The NumPy documentation is available [here](https://numpy.org/doc/1.24/).\n",
    "\n",
    "IPython display is a module in the IPython interactive computing environment that provides a set of functions for displaying various types of media in the Jupyter notebook or other IPython-compatible environments.For example, you can use the display() function to display an object in a notebook cell (for example an audio object created with the Audio() function).\n",
    "\n",
    "Matplotlib is a popular Python library that allows users to create a wide range of visualizations using a simple and intuitive syntax.\n",
    "\n",
    "The python package LibROSA provides several functions to analyze and process audio signals.\n",
    "\n",
    "Librosa is a Python package for analyzing and processing audio signals. It provides a wide range of tools for tasks such as loading and manipulating audio files, extracting features from audio signals, and visualizing and playing back audio data. Librosa is a popular library for use in music information retrieval (MIR) and speech analysis.\n",
    "\n",
    "The SciPy package provides algorithms for scientific computing in Python.\n",
    "\n",
    "The math module provides access to the mathematical functions defined by the C standard but that cannot be used with complex numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f431683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import scipy.signal as sig\n",
    "from scipy.fft import fft\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28ab25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83069a511750f98560e14ad758b1f7a4",
     "grade": false,
     "grade_id": "cell-81ae063c7c09bbad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Speech data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01aaf6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d984968fe716a2f2fe5e55e5a05f349",
     "grade": false,
     "grade_id": "cell-e06258eb4c50ceb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Harvard sentences\n",
    "\n",
    "The Harvard sentences are a set of standardized phrases used for speech testing and evaluation of audio equipment, such as telephones, radios, and hearing aids. They were developed by researchers at Harvard University in the early 20th century and have since been widely used as a benchmark for audio quality.\n",
    "\n",
    "The original set of Harvard sentences consisted of ten lists of ten phrases each, which were carefully designed to include a wide range of speech sounds and phonetic contrasts. Each sentence is relatively short and simple, typically consisting of five to ten words, and is meant to be easy to pronounce and understand.\n",
    "\n",
    "he Harvard sentences have been revised and expanded over the years, with newer versions containing up to 720 sentences. They are still widely used today in audio testing and research, and have become a standard tool for evaluating speech recognition systems and other audio technologies.\n",
    "\n",
    "The full list of Harvard sentences is available here: https://www.cs.columbia.edu/~hgs/audio/harvard.html\n",
    "\n",
    "Philippa Demonte collected a high quality digital audio speech corpus of the Harvard sentences in its entirety (720 phonetically-balanced sentences) recorded December 2018 at the University of Salford with a female native British English speaker. The corpus is avalaible [here](https://salford.figshare.com/articles/media/Speech_corpus_-_Harvard_-_raw_audio/7862666?backTo=/collections/HARVARD_speech_corpus_-_audio_recording_2019/4437578)\n",
    "\n",
    "The list01 include the following sentences:\n",
    "\n",
    "1. The birch canoe slid on the smooth planks.\n",
    "2. Glue the sheet to the dark blue background.\n",
    "3. It's easy to tell the depth of a well.\n",
    "4. These days a chicken leg is a rare dish.\n",
    "5. Rice is often served in round bowls.\n",
    "6. The juice of lemons makes fine punch.\n",
    "7. The box was thrown beside the parked truck.\n",
    "8. The hogs were fed chopped corn and garbage.\n",
    "9. Four hours of steady work faced us.\n",
    "10. A large size in stockings is hard to sell.\n",
    "\n",
    "\n",
    "The next code block fetches the audio file with sentences of list01, loads and converts the sampling rate to 22050 samples/second using the librosa.load() function.\n",
    "\n",
    "Note: you may want to comment the \"!wget\" after the first run to avoid waiting for the download once you have the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O harvard01.wav https://salford.figshare.com/ndownloader/files/14630270\n",
    "sr = 22050\n",
    "harvard01, sr = librosa.load(\"harvard01.wav\", sr=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f8799",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0dc6a2306c3306510de97d5f0ea4509f",
     "grade": false,
     "grade_id": "cell-3e774985c34521ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Adjust dynamic range\n",
    "\n",
    "The librosa.load() function converts the dynamic range of the samples encoded in the file to the range $[-1,1]$, but does not performe any amplitude scaling.\n",
    "\n",
    "Adjust the dynamic range to -3dB full scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f386c20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe6431bb213be9d1533e62f89c5ecd1f",
     "grade": false,
     "grade_id": "cell-e1d8ff06e4f1b873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# adjust dynamic range to -3dB full scale\n",
    "harvard01 = (10**(-3/20)) * harvard01 / np.max(np.abs(harvard01))\n",
    "\n",
    "display(Audio(harvard01, rate=sr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74e603",
   "metadata": {},
   "source": [
    "### Second Harvard sentence\n",
    "\n",
    "The second Harvard sentence starts at $t=15.5 s$ and has a duration of $2.8 s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424466d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec0945bb4f9bfe470df32044b20e277a",
     "grade": false,
     "grade_id": "cell-2f148cd7456c9bea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# location of the first utterance\n",
    "utt_start = 15.5\n",
    "utt_end = utt_start + 2.8\n",
    "+8\n",
    "utt = harvard01[int(utt_start*sr):int(utt_end*sr)]\n",
    "\n",
    "display(Audio(utt, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf7129",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47f2c691a90b4692d6f718484a5e4e92",
     "grade": false,
     "grade_id": "TimeVis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Time domain visualization\n",
    "\n",
    "The python package LibROSA provides several functions to analyze and process audio signals. The `librosa.display.waveshow()` function can be used to display long signals in a compact format. Depending on the size of the signal to be displayed it adaptively switches between a raw samples-based view and an amplitude-envelope view.\n",
    "\n",
    "Visualize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a554d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a934c2cdc49668955c909449251e42f",
     "grade": false,
     "grade_id": "TimeVisCode",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "librosa.display.waveshow(utt, sr=sr, ax=ax)\n",
    "\n",
    "display(Audio(utt, rate=sr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4116164",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "013a28b50d35fffdd3915ee548a5e971",
     "grade": false,
     "grade_id": "cell-f6f02162762c3ef4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualise a segment of the signal\n",
    "\n",
    "The speech signal is an example of a non-stationary signal. To analyze the recording with more detail we can use an helper function to plot smaller segments of the signal. The libROSA waveshow() function is able to show the individual signal samples when the plot contains a sufficiently small number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c4810",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e0a54bcc70a449f13084118d4fad5b",
     "grade": false,
     "grade_id": "cell-96f274a50fcfb0e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def waveshow_seg(x, fs, tmin=0, tmax=0):\n",
    "    if (tmin < 0) or (tmin > x.size/fs):\n",
    "        tmin = 0\n",
    "    if (tmax <= 0) or (tmax > x.size/fs): \n",
    "        tmax = x.size/fs\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    ax.set(xlim=[tmin, tmax])\n",
    "    librosa.display.waveshow(x, sr=fs, axis='ms')\n",
    "    return\n",
    "\n",
    "start = 0.3\n",
    "end = start + 0.01\n",
    "waveshow_seg(utt, sr, tmin=start, tmax=end)\n",
    "\n",
    "# select the segment for playing\n",
    "n_seg = np.arange(np.floor(start*sr), np.ceil(end*sr), dtype=int)\n",
    "display(Audio(utt[n_seg], rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d076e1",
   "metadata": {},
   "source": [
    "### Save the utterance\n",
    "\n",
    "\n",
    "Save the utterance into a wav file and use Audacity to locate the begining and end of the word \"sheet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('utt.wav', utt, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df231bb8",
   "metadata": {},
   "source": [
    "### T2: Locate the word \"blue\"\n",
    "\n",
    "Initialize the variables `word_start` and `word_end` with the time instants inside `utt` were the word \"blue\" is located. You can use Audacity for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac9e4d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4271c0223ffaa19f861d2957496315b6",
     "grade": false,
     "grade_id": "T2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "word = utt[int(word_start*sr):int(word_end*sr)]\n",
    "\n",
    "display(Audio(word, rate=sr))\n",
    "waveshow_seg(word, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8133a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06786a5e93229bcb1a74332eb342f410",
     "grade": true,
     "grade_id": "T2t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (word_end - word_start < 0.3) and (word_end - word_start > 0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6186e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c65faa5aee5d35acaa7a9a328407233f",
     "grade": false,
     "grade_id": "cell-fc90568c1d4de78f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T3: Locate the first vowel I\n",
    "\n",
    "Define the variables `vowelI_start`and `vowelI_end` with the begining and end of the firsr vowel I in seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afee678",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da1e6d6f3bc6a76f94fb925090b75f3e",
     "grade": false,
     "grade_id": "T3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "vowelI_middle = vowelI_start + 0.5*(vowelI_end-vowelI_start)\n",
    "\n",
    "\n",
    "vowelI = utt[int(vowelI_start*sr):int(vowelI_end*sr)]\n",
    "display(Audio(vowelI, rate=sr))\n",
    "waveshow_seg(vowelI, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a4a3e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "493ec99a48bc58f14fe3145235246fbc",
     "grade": true,
     "grade_id": "T3t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (vowelI_end - vowelI_start < 0.13) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ccc20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "096bb5d8eca3f2cb6b662d5b661ae76a",
     "grade": false,
     "grade_id": "cell-ed82bda619fc28c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T4: Estimate the fundamental frequency at the center of vowel I\n",
    "\n",
    "Estimate the fundamental frequency in the middle of the vowel and initialize the variable `vowelI_f0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d9cf4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d495efe686a055a4d295984c12cea3f",
     "grade": false,
     "grade_id": "T4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"vowel I fundamental frequency is {vowelI_f0:.2f} Hz\")\n",
    "\n",
    "mid = len(vowelI)//2/sr\n",
    "waveshow_seg(vowelI, sr, tmin=mid-1/vowelI_f0, tmax=mid+1/vowelI_f0)\n",
    "plt.grid()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787a2b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ace335e7ebdc031587440aeccaed785",
     "grade": true,
     "grade_id": "T4t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (vowelI_f0 > 250) and (vowelI_f0 < 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb2e37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f54e59038bb6c3cfb736bcd07a7d1ad",
     "grade": false,
     "grade_id": "FreqVis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Frequency domain visualization\n",
    "\n",
    "The spectrum is a representation of a signal in terms of magnitude and phase characteristics as a function of frequency. The discrete-time Fourier transform (DTFT) can be used to compute the frequency representation of a signal. However, the DTFT is a function of a real variable $\\omega \\in \\mathbb{R}$ that needs to be sampled for use in a digital computer.\n",
    "\n",
    "The sampled representation of the DTFT is called the discrete Fourier transform (DFT) that can be very efficiently computed using the fast Fourier transform (FFT):\n",
    "$$\n",
    "X(k) = \\sum_{n=0}^{N-1} x(n) e^{-j \\frac{2\\pi}{N} kn},\\; 0 \\leq k \\leq N-1\n",
    "$$\n",
    "\n",
    "Given the periodicity of the complex exponential $e^{-j \\frac{2\\pi}{N} kn}$, the definition of $X(k)$ results in a periodic sequence of period $N$. This is prevented by limiting the range of $k$.\n",
    "\n",
    "The `mag_spectrum()` function plots $|X(k)|$, the magnitude of the spectrum of the sequence $x(n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14df765",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8da725df371b9539b3ffb3766dee4bc6",
     "grade": false,
     "grade_id": "cell-4696c65e35830185",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mag_spectrum(x, fs, fmin=0, fmax=0, ax=None):\n",
    "    \"\"\"\n",
    "    Plot the magnitude spectrum of sequence x using the sampling frequency fs\n",
    "    \"\"\"\n",
    "\n",
    "    X = fft(x)\n",
    "    X_mag_dB = np.absolute(X)\n",
    "    \n",
    "    \n",
    "    # the DFT samples the frequency range with N points\n",
    "    f = np.linspace(0,fs, X.size)\n",
    "    \n",
    "    # plot frequency range\n",
    "    if (fmin < 0 or fmin>fs):\n",
    "        fmin = 0\n",
    "    if (fmax <= 0 or fmax>fs):\n",
    "        fmax = fs/2\n",
    "    \n",
    "    # plot\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "    \n",
    "    ax.set(xlim=(fmin, fmax))\n",
    "    ax.plot(f, X_mag_dB)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.grid()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833536b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45fefc9d09e70b4639ebcdf96d2acde2",
     "grade": false,
     "grade_id": "cell-62f88067ace78023",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Vowel I full magnitude spectrum\n",
    "\n",
    "Use the mag_spectrum function to show the peridodicity of the DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e234d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_spectrum(vowelI, sr, fmin=0, fmax=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902203a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5ec977a20f1efe4974c8daddfbf7430",
     "grade": false,
     "grade_id": "cell-2a01b706b67da57d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Symmetry Property of the DFT\n",
    "\n",
    "As shown in the previous plot, if $x(n)$ is a sequence of real values, the coefficients of it's DFT have the property that $|X(k)| = |X(N-k)|$. For this reason, we can limit the range of the spectrum to half of the sampling frequency without loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_spectrum(vowelI, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fad3d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7d186ebe988426fa398bcbb31a6cb86",
     "grade": false,
     "grade_id": "cell-e3e18a0e0881ea72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Decibels relative to full scale (dBFS)\n",
    "\n",
    "Decibels relative to full scale (dBFS) is a measure of amplitude levels in decibels.\n",
    "\n",
    "If $v$ is the amplitude of the signal that we want to measure and $v_{0}$ a reference amplitude, the amplitude ratio in decibels is:\n",
    "$$\n",
    "L_{dB} = 20 \\log_{10}\\left( \\frac{v}{v_{0}}\\right)\n",
    "$$\n",
    "\n",
    "The measure of decibels realtive to full scale (dBFS) assumes that $v_0$ is the maximum possible value for $v$ such that:\n",
    "$$\n",
    "L_{dBFS}(v_{0}) = 0\\ dB\n",
    "$$\n",
    "\n",
    "When the amplitude is at 50% of the maximum level:\n",
    "$$\n",
    "L_{dBFS}\\left( \\frac{v_{0}}{2} \\right) \\approx -6\\ dB\n",
    "$$\n",
    "\n",
    "Many signals resulting from an analog to digital conversion are represented in an amplitude range of $[-1,1]$, which means that $v_{0}=1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfabc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a8deed8017d9f41413a1fcb0b21a652",
     "grade": false,
     "grade_id": "cell-115c986e0e2baa1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mag_spectrum_dB(x, fs, fmin=0, fmax=0, ax=None):\n",
    "    \"\"\"\n",
    "    Plot the magnitude spectrum in decibels of sequence x using the sampling frequency fs\n",
    "    \"\"\"\n",
    "\n",
    "    X = fft(x)\n",
    "    X_mag_dB = 20*np.log10(np.absolute(X))\n",
    "    \n",
    "    \n",
    "    # the DFT samples the frequency range with N points\n",
    "    f = np.linspace(0,fs, X.size)\n",
    "\n",
    "    # plot frequency range\n",
    "    if (fmin < 0 or fmin>fs):\n",
    "        fmin = 0\n",
    "    if (fmax <= 0 or fmax>fs):\n",
    "        fmax = fs/2\n",
    "    \n",
    "    # plot\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.set(xlim=(fmin, fmax))\n",
    "    ax.plot(f, X_mag_dB)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.grid()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f251843",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af2138277559ce01ca35bc6e5bb29a12",
     "grade": false,
     "grade_id": "cell-9482f21da9cc585e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Vowel I magnitude spectrum in dB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_spectrum_dB(vowelI, sr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f483f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f9b5043e3acc51c5fbdf747183c94b7",
     "grade": false,
     "grade_id": "cell-aecbae989dccfce2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T5: Linear vs logarithmic amplitudes\n",
    "\n",
    "In the following text box compare the differences between the magnitude spectrum expressed in linear or logarithmic amplitudes. What are the advantages of the representation in decibels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70d1ed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18ffd7fa9400b7b06b6c14ce9388c8a7",
     "grade": true,
     "grade_id": "cell-f543d18fa2685d78",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d9286",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9de1b06a4007176094e80e3a15aff607",
     "grade": false,
     "grade_id": "cell-905194ea3c0cdccd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Windowing\n",
    "\n",
    "The function `mag_spectrum_dB()` computes da DFT with the same lenght as the input vector `x`. However, the FFT is more efficient when the lenght of the signal is a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "win = np.hanning(N)\n",
    "midpoint = int(sr*(vowelI_middle-vowelI_start))\n",
    "vowI = vowelI[midpoint-(N//2):midpoint+(N//2)]*win\n",
    "librosa.display.waveshow(vowI, sr=sr)\n",
    "mag_spectrum_dB(vowI, sr, fmin=0, fmax=sr/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df81a73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c3b660b15851d8d0c406c815181a640",
     "grade": false,
     "grade_id": "cell-af3fbdae64eb47a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Narrow-band magnitude spectrum\n",
    "\n",
    "The DFT samples the DTFT in as many samples as the length of the signal. To have a higher frequency resolution (a narrow-band analysis) we need longer window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "win = np.hanning(N)\n",
    "midpoint = int(sr*(vowelI_middle-vowelI_start))\n",
    "vowI_1024 = vowelI[midpoint-(N//2):midpoint+(N//2)]*win\n",
    "librosa.display.waveshow(vowI_1024, sr=sr)\n",
    "mag_spectrum_dB(vowI_1024, sr, fmin=0, fmax=sr/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba27cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d18fba5364ba8468175eaf60ad3bd94",
     "grade": false,
     "grade_id": "cell-ea6f5aa14b234056",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Wide-band magnitude spectrum\n",
    "\n",
    "With a lower frequency resolution (a wide-band analysis) the envelope of the magnitude spectrum show the resonances of the vocal tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "win = np.hanning(N)\n",
    "midpoint = int(sr*(vowelI_middle-vowelI_start))\n",
    "vowI_256 = vowelI[midpoint-(N//2):midpoint+(N//2)]*win\n",
    "librosa.display.waveshow(vowI_256, sr=sr)\n",
    "mag_spectrum_dB(vowI_256, sr, fmin=0, fmax=sr/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88541745",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8103854e9dc3f85d1ae69c4336978d15",
     "grade": false,
     "grade_id": "cell-ae8609fa5256e1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Harmonic spectrum\n",
    "\n",
    "The quasi-periodicity of the vowel sound results in the presence of harmonic peaks in the magnitude spectrum.\n",
    "\n",
    "The frequency representation of the harmonic peaks depend on the window function used to weight the time samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d7fcb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a37773cc310885b0d1e725dc088f395",
     "grade": false,
     "grade_id": "cell-d70e89b9e0268fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N = 1024\n",
    "win1 = np.ones(N)\n",
    "win2 = np.hanning(N)\n",
    "midpoint = int(sr*(vowelI_middle-vowelI_start))\n",
    "vowI_win1 = vowelI[midpoint-(N//2):midpoint+(N//2)]*win1\n",
    "vowI_win2 = vowelI[midpoint-(N//2):midpoint+(N//2)]*win2\n",
    "librosa.display.waveshow(vowI_win1, sr=sr)\n",
    "librosa.display.waveshow(vowI_win2, sr=sr)\n",
    "ax = mag_spectrum_dB(vowI_win1, sr, fmin=0, fmax=sr/2)\n",
    "mag_spectrum_dB(vowI_win2, sr, fmin=0, fmax=sr/2, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd29d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a991b0c5d4e12f6479b3efbe9276e6d3",
     "grade": false,
     "grade_id": "cell-5567ccb2a6c1d7cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T6: Differences between windows\n",
    "\n",
    "In the next text box explain the diferences observed is the magnitude spectrum resulting from the selection of the window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5848eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a43761737c8d79a0125be8975a4d39a",
     "grade": true,
     "grade_id": "cell-bbf5c3788229e40c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728c022",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c41c30745560bcf07cb22d6f0e9f9a55",
     "grade": false,
     "grade_id": "cell-999b5f5a58a17161",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Linear Prediction Analysis\n",
    "\n",
    "Linear prediction tries to predict a signal sample $\\hat{s}(n)$ using a linear combination of the signal's past samples:\n",
    "$$\n",
    "\\hat{s}(n) = \\sum_{k=1}^{P} a_k s(n-k)\n",
    "$$\n",
    "\n",
    "The prediction error $e(n)$ is called the residue:\n",
    "$$\n",
    "e(n) = s(n) - \\sum_{k=1}^{P} a_k s(n-k)\n",
    "$$\n",
    "\n",
    "This difference equation as the form of an all-zero filter with a transfer function $A(z)$ that is a polynomial in $z$:\n",
    "$$\n",
    "A(z) = 1 - \\sum_{k=1}^{P} a_k z^{-k}\n",
    "$$\n",
    "\n",
    "The inverse of this filter is an all-pole filter that can be seen as similar to the vocal tract transfer function. In this case the residue can also be seen as an estimate of the glottal excitation.\n",
    "\n",
    "If the signal is assumed to be quasi-stationary, the linear prediction coefficients $a_k$ can be found by finding the values that minimizes the energy of the prediction error (residue):\n",
    "$$\n",
    "a_k = \\text{argmin}  \\sum_{n=-\\infty}^{+\\infty} \\left( e(n) \\right)^2\n",
    "$$\n",
    "\n",
    "This is an optimization problem where we want to minimize the error function:\n",
    "$$\n",
    "\\cal{E} = \\sum_{n=-\\infty}^{+\\infty} \\left( s(n) - \\sum_{k=1}^{P} a_k s(n-k) \\right)^2\n",
    "$$\n",
    "\n",
    "Setting the derivative of the error to zero\n",
    "$$\n",
    "\\frac{d \\cal{E}}{d a_k} = 2 \\sum_{n=-\\infty}^{+\\infty} \\left( s(n) - \\sum_{k=1}^{P} a_k s(n-k) \\right) s(n-k) = 0\n",
    "$$\n",
    "\n",
    "Results in a set of $P$ equations with P unknowns ($a_k$). Using the autocorrelation function:\n",
    "$$\n",
    "R(k) = \\sum_{n=-\\infty}^{+\\infty} s(n) s(n-k)\n",
    "$$\n",
    "\n",
    "The system of equations becomes:\n",
    "$$\n",
    "\\mathbf{R} \\mathbf{a} = \\mathbf{\\gamma}\n",
    "$$\n",
    "where $\\mathbf{R}$ is a $P \\times P$ matrix with elements $R_{k,i}=R(|k-i|)$, $\\mathbf{a}$ is $P \\times 1$ vector with the lpc coefficients $a_k$ and $\\mathbf{\\gamma}$ is $P \\times 1$ vector with $\\gamma_k = R(k)$.\n",
    "\n",
    "The solution is:\n",
    "$$\n",
    "\\mathbf{a} = R^{-1} \\mathbf{\\gamma}\n",
    "$$\n",
    "\n",
    "All the elements along the diagonals of the $\\mathbf{R}$ matrix have the same value, that is, $\\mathbf{R}$ is a Toeplitz matrix. The system of equations can be solved using the Levinson-Durbin recursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ce70a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "515ddea397f296cf737a285fbd857e5a",
     "grade": false,
     "grade_id": "cell-e6fef87019f406da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bias_autocorr(signal, order):\n",
    "    \"\"\" Computes the autocorrelation of signal up to the order of the LPC analysis\"\"\"\n",
    "    N = len(signal)\n",
    "    r = np.zeros(order+1)\n",
    "    r[0] = np.sum(signal**2)/N\n",
    "    for k in range(1,order+1):\n",
    "        r[k] = np.sum(signal[k:]*signal[:-k])/N\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52294af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8c6dd1cd3e1edf761469ecf01f1f972",
     "grade": false,
     "grade_id": "cell-e9e82ce3cfc0239f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def levison_durbin(r, order):\n",
    "    \"\"\"Solves the levinson-durbin recursion for the LPC analysis\"\"\"\n",
    "    g = r[1] / r[0]\n",
    "    a = np.array([g])\n",
    "    v = (1 - g**2) * r[0]\n",
    "    for m in range(1, order):\n",
    "        g = (r[m+1] - np.dot(a, r[1:m+1])) / v\n",
    "        a = np.r_[ g, a - g*a[m-1::-1] ]\n",
    "        v *= 1 - g**2\n",
    "    return np.r_[1, -a[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0c4c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a745d4e7bbe3e05eec7b182cb65b2f1e",
     "grade": false,
     "grade_id": "cell-e1e02168153d25b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lpc(signal, order):\n",
    "    \"\"\"Computes the LPC analysis of signal x up to order order\"\"\"\n",
    "    return levison_durbin(bias_autocorr(signal, order), order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1e0f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e430b72266665622e4aca86df93490b1",
     "grade": false,
     "grade_id": "cell-22b9c292c62312a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### LPC spectrum\n",
    "\n",
    "The LPC spectrum is the frequency response of the all-pole system with the coefficients resulting from LPC analysis. The transfer function of the system is:\n",
    "$$\n",
    "H(z) = \\frac{K}{A(z)}\n",
    "$$\n",
    "where $K$ is a gain factor.\n",
    "\n",
    "To find the frequency response $z=e^{j\\omega}$:\n",
    "$$\n",
    "H(e^{j\\omega}) = \\frac{K}{A(e^{j\\omega})}\n",
    "$$\n",
    "\n",
    "The inverse filter is an all-zero filter, that is, a finite impulse response filter:\n",
    "$$\n",
    "H^{-1}(e^{j\\omega}) = A(e^{j\\omega})\n",
    "$$\n",
    "with impulse response:\n",
    "$$\n",
    "h^{-1}(n) = 1 - \\sum_{k=1}^{P} a_k \\delta(n-k)\n",
    "$$\n",
    "where $\\delta(n)$ is the unit impulse.\n",
    "\n",
    "The frequency response can be computed by inverting the DFT of the impulse response of the inverse filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b45291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7942c3fa5f794a92c88fbf58f59df40",
     "grade": false,
     "grade_id": "cell-322c843967a5519b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lpc_spectrum_dB(x, fs, order, fmin=0, fmax=0, ax=None):\n",
    "    \"\"\"\n",
    "    Plot the magnitude spectrum of sequence x\n",
    "    using the sampling frequency fs\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.divide(1.0, fft(lpc(x, order), len(x)))\n",
    "    X_mag_dB = 20*np.log10(np.abs(X))\n",
    "    \n",
    "    # the DFT samples the frequency range with N points\n",
    "    f = np.linspace(0,fs, X.size)\n",
    "    \n",
    "    # plot frequency range\n",
    "    if (fmin < 0 or fmin>fs):\n",
    "        fmin = 0\n",
    "    if (fmax <= 0 or fmax>fs):\n",
    "        fmax = fs/2\n",
    "    \n",
    "    # plot\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.set(xlim=(fmin, fmax))\n",
    "    ax.plot(f, X_mag_dB)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.grid()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6081206",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4d8892a8a9424a86670448f3c9b2901",
     "grade": false,
     "grade_id": "cell-67207c936d6aa816",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### LPC order\n",
    "\n",
    "The order of the LPC analysis should be adjusted in order to model the resonances of the vocal tract in the selected frequency range.\n",
    "\n",
    "The analysis of a lossless tube show that it has one resonance in every 1000 Hz frequency band. Since each ressonance requires 2 filter coefficients, it is common to chose an LPC order equal to sampling frequency divide by 1000 plus an addicional ressonance to allow the presence of a nasal zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ab285",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "win = np.hanning(N)\n",
    "order = sr//1000 + 2\n",
    "midpoint = int(sr*(vowelI_middle-vowelI_start))\n",
    "vowI_1024 = vowelI[midpoint-(N//2):midpoint+(N//2)]*win\n",
    "ax = mag_spectrum_dB(vowI_1024, sr)\n",
    "ax = lpc_spectrum_dB(vowI_1024, sr, order, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870cb68",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9c1857062df5e6ccb647179fa9fb344",
     "grade": false,
     "grade_id": "cell-60d553966c087a4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T7: Compute the LPC error or residue\n",
    "\n",
    "The all-zeros filter can be used to estimate the LPC error or residue. The residue signal should have less energy than the original signal and shows periodic pulses.\n",
    "\n",
    "If we assume that the LPC filter is an estimate of the vocal tract, residue signal is an estimate of the voicing source necessary to produce the vowel.\n",
    "\n",
    "The function scipy.signal.lfilter() implements a difference equation. Initialize the vectors `b` and `a` with the filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd5af7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad3fda58097bf5f5c763fddb0ae704f",
     "grade": false,
     "grade_id": "T7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "vowI_1024_resid = sig.lfilter(b, a, vowI_1024)\n",
    "librosa.display.waveshow(vowI_1024, sr=sr)\n",
    "librosa.display.waveshow(vowI_1024_resid, sr=sr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0cae0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61718a7113266e1a8e7d986b191ab607",
     "grade": true,
     "grade_id": "T7t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.average(np.abs(vowI_1024_resid)) < np.average(np.abs(vowI_1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb94ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e28d0c702889343579133f8fb1cffa47",
     "grade": false,
     "grade_id": "cell-78ab176377fd47f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Non-stationary signals: signal framing\n",
    "\n",
    "Most of real-world signals are non-stationary. Since most signal processing techniques assume that the signal is stationary, it is common to split the original signal into short segments, called frames. To assume that the signal is quasi-stationary in these shorter segments frames are typically chosen to be of 10 to 100 ms in duration. The variable `frame_length` contais the number of samples in each frame.\n",
    "\n",
    "To prevent large discontinuities when using frames to extract features from the signal, it is also common to use overlapping frames. This means that the next analysis frame includes samples that were also included is previous frames. The variable `hop_length` contais the number of samples between the start of two consecutive frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 1024\n",
    "hop_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24592d79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7cdc7796399326a8dea64872807a521",
     "grade": false,
     "grade_id": "cell-68027bea5f7bf6e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Zero padding\n",
    "\n",
    "In many application we need to reconstruct a signal by recombining overlapping frames. To be able to reconstruct a signal with, at least, the same length of the original the signal needs to be extended with zeros. This is called zero padding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3e355",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3118d9e75be4426e3fbbf2243c3f2812",
     "grade": false,
     "grade_id": "cell-121f298d03a737e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pad_signal(x, frame_length, hop_length):\n",
    "    \"\"\"Pads the signal x so that it can be split into frames of length frame_length with hop_length in between\"\"\"\n",
    "    N = len(x)\n",
    "    N_frames = N//hop_length + (N%hop_length > 0)\n",
    "    x_padded = np.zeros((N_frames-1)*hop_length + frame_length)\n",
    "    x_padded[:N] = x\n",
    "    return x_padded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf66b3",
   "metadata": {},
   "source": [
    "#### Test zero padding\n",
    "\n",
    "To test the pad_signal() function we will use a we will use a chirp signal. A chirp signal is a type of signal that varies its frequency over time. In this case we will use a linear chirp signal with decreasing frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = 1\n",
    "c_sr = 22050\n",
    "t = np.linspace(0, dur, int(dur*c_sr), endpoint=False)\n",
    "fmax = 300\n",
    "fmin = 150\n",
    "\n",
    "f = np.linspace(fmax, fmin, len(t))\n",
    "c = np.sin(2*np.pi*f*t)\n",
    "display(Audio(c, rate=sr))\n",
    "\n",
    "c_pad = pad_signal(c, frame_length, hop_length)\n",
    "c_nframes = (len(c)+hop_length-frame_length)//hop_length\n",
    "c_pad_nframes = (len(c_pad)+hop_length-frame_length)//hop_length\n",
    "print(f\"Length of c signal: {len(c)}\")\n",
    "print(f\"Number of frames of c signal: {c_nframes}\")\n",
    "print(f\"Number of frames of c_pad signal: {c_pad_nframes}\")\n",
    "print(f\"Length of reconstructed signal {c_pad_nframes}x{hop_length}={c_pad_nframes*hop_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b132706",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e92e64280e24448ee3caa1213211f611",
     "grade": false,
     "grade_id": "cell-604fe68c6de34ca9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### short-time Fourier transform (STFT)\n",
    "\n",
    "The short-time Fourier transform is a type of Fourier analysis used to determine the frequency content of a signal over short, fixed-length time intervals. It is used in many applications, such as speech processing and musical analysis. The STFT is based on the conventional Fourier transform, but it divides the signal into overlapping segments and then performs a Fourier analysis for each segment. This results in a two-dimensional representation of the signal, where the frequency is on one axis and time on the other. Different resolutions can be obtained for analyzing different aspects of the signal by varying the size and position of the segments.\n",
    "\n",
    "The signal segmentation is performed by multiplying the signal by a window function $w(n)$ that is zero-valued outside a specified interval. For example the rectangular window:\n",
    "$$\n",
    "w_{r}(n) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\le n \\le M-1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The short-time Fourier transform, $X(n, \\omega)$ is a two-dimensional representation of the signal $x(n)$:\n",
    "$$\n",
    "X(n, \\omega) = \\sum_{m=-\\infty}^{+\\infty} x(n+m)w(m) e^{-j\\omega (n+m)} \n",
    "$$\n",
    "\n",
    "If we use the discrete Fourier transform (DFT):\n",
    "\n",
    "$$\n",
    "X(n,k) = \\sum_{m=0}^{M-1}x(n+m)w(m) e^{-j \\frac{2\\pi}{M}(n+m)},\\ 0\\le k \\le M-1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcd9f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fcff3b90914d582965856a14234ee6e",
     "grade": false,
     "grade_id": "cell-c629cad63c5254e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Spectrogram of a signal\n",
    "\n",
    "The spectrogram of a time-domain signal is a representation of the magnitude of the short-time Fourier transform (STFT) ($X(n,k)$) of a signal.\n",
    "\n",
    "To facilitate the analysis of the signal, it is common to use the time axis in seconds or milliseconds and the frequency axis in Hz. The value of the amplitude of the spectrum at each point is represented with a darker color for low values and brighter color for higher values.\n",
    "\n",
    "For better visualization of the entire range of amplitudes, it is frequent to represent them in decibels (dB).\n",
    "\n",
    "The short-time Fourier transform can be computed with the `librosa.stft()` function. The resulting linear amplitudes need to be converted to dB. The function `librosa.display.specshow()` function can then be used to display the spectrogram as a frequency versus time representation of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e796c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f117806a7239e13f101e6be47eaf52c3",
     "grade": false,
     "grade_id": "cell-d3f27253635af599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spectrogram(x, fs, n_fft=512, win_length=512, hop_length=64, window='hann'):\n",
    "    D = librosa.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window=window)\n",
    "    DAbsdB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    return DAbsdB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcd054",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a37e68eb4f78dd3e174863f4bb9c65cc",
     "grade": false,
     "grade_id": "cell-49d6b56732220902",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Spectrogram of the word \"blue\"\n",
    "\n",
    "Use the spectrogram() function to plot the spectrogram of the word \"blue\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44001f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DAbsdB = spectrogram(word, sr)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "img = librosa.display.specshow(DAbsdB, ax=ax, x_axis='time', y_axis='linear')\n",
    "ax.set(title='Linear-frequency power spectrogram')\n",
    "ax.label_outer()\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "\n",
    "Audio(data=word, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf60f08",
   "metadata": {},
   "source": [
    "#### Wave and spectrogram visualization\n",
    "\n",
    "It is frequently useful to have a simultaneous view of both the spectrogram and the time domain waveform aligned in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_wave_show(x, fs, tmin=0, tmax=0, n_fft=1024, win_length=1024, hop_length=128, window='hann'):\n",
    "    \"\"\"\n",
    "    Plot a spectrogram and a waveform of a signal x\n",
    "    \"\"\"\n",
    "    if (tmax == 0):\n",
    "        tmax = x.shape[0]/fs\n",
    "    nseg = np.arange(np.floor(tmin*fs), np.ceil(tmax*fs), dtype=int)\n",
    "\n",
    "    D = librosa.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window=window)\n",
    "    DAbsdB = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8), nrows=2, sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n",
    "    ax[0].set(xlim=[tmin, tmax])\n",
    "    librosa.display.specshow(DAbsdB, n_fft=n_fft, win_length=win_length, hop_length=hop_length, sr=fs, ax=ax[0], x_axis='time', y_axis='linear')\n",
    "    ax[0].set(title='Linear-frequency power spectrogram')\n",
    "    librosa.display.waveshow(x, sr=fs, axis='time')\n",
    "    display(Audio(data=x[nseg], rate=fs))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "img, ax = spec_wave_show(word, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0b509",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7734b458287f54bf99e9b14e13fe1e4",
     "grade": false,
     "grade_id": "cell-22ddc06915514e28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T8: Visualization of the plosive\n",
    "\n",
    "In the previous spectrogram the plosive [b] is not visible in the spectrogram. Selected a frame size to make it more noticeable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f8b2d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cb2ec11c81447fb0f844ef1a8184e31",
     "grade": false,
     "grade_id": "T8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "img, ax = spec_wave_show(word, sr, n_fft=fsize, win_length=fsize, hop_length=fsize//4, window='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61d2be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e8f945e055ba6f38724f490cc641a30",
     "grade": true,
     "grade_id": "T8t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (fsize & (fsize-1) == 0) and fsize != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f732af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "978539e0211b16dd4645ac626108dfde",
     "grade": false,
     "grade_id": "cell-15b7cc894b1bce59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fundamental frequency estimation and voice/unvoice detection\n",
    "\n",
    "The fundamental frequency is the frequency of the first harmonic of a periodic signal. In speech processing the fundamental frequency is often referred by f0 or pitch.\n",
    "\n",
    "In this lab we will use the estimator pyin() provide by the libROSA package.\n",
    "\n",
    "To show the performance of the algorithm in tracking the first harmonic of the signal we can plot the spectrogram in a logarithmic frequency scale and overlap the f0 values produced by the estimator.\n",
    "\n",
    "You can see the f0 decay typical of a declarative utterance. You also observe the intonation break after the word \"canoe\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c95113",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, voiced_flag, voiced_probs = librosa.pyin(utt, fmin=100, fmax=360)\n",
    "times = librosa.times_like(f0)\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(utt)), ref=np.max)\n",
    "fig, ax = plt.subplots(figsize=(10,8), nrows=2, sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n",
    "img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax[0])\n",
    "ax[0].set(title='pYIN fundamental frequency estimation')\n",
    "#fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "ax[0].plot(times, f0, label='f0', color='cyan', linewidth=4)\n",
    "ax[0].legend(loc='upper right')\n",
    "librosa.display.waveshow(utt, sr=sr, axis='time', ax=ax[1])\n",
    "plt.tight_layout()\n",
    "display(Audio(data=utt, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b6bc9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2706ed4c428c53506b49dc5f19ccad51",
     "grade": false,
     "grade_id": "cell-2657895e99c008f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Interpolation of f0 values\n",
    "\n",
    "The frame-based fundamental frequency estimator produces a f0 value for every frame. We want to interpolate these values to have a value of f0 for every sample of the signal.\n",
    "\n",
    "The function scipy.interpolate.interp1d() can help with the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05d856",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f55638245768bdbbc21bb362ba1d1a8d",
     "grade": false,
     "grade_id": "cell-7ba7b6bf85014039",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def sig_f0(x, sr, frame_length, hop_length):\n",
    "    \"\"\"Estimates and interpolates the F0 for every time sample of given signal x\"\"\" \n",
    "    t = np.linspace(0, len(x)/sr, len(x))\n",
    "    x_pad = pad_signal(x, frame_length, hop_length)\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(x_pad, fmin=60, fmax=360, sr=sr, \n",
    "                                                 frame_length=frame_length, \n",
    "                                                 hop_length=hop_length)\n",
    "    t_f0 = np.linspace(0, len(x)/sr, len(f0))\n",
    "    # Interpolate the F0 estimates to cover the entire time range\n",
    "    interpf0 = interp1d(t_f0, f0)\n",
    "    f0i = interpf0(t)\n",
    "    f0i = np.nan_to_num(f0i, nan=0)\n",
    "    return f0i\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445b18f",
   "metadata": {},
   "source": [
    "#### Visualize the interpolated f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9012316",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 1024\n",
    "hop = 256\n",
    "utt_f0 = sig_f0(utt, sr, fsize, hop)\n",
    "t = np.linspace(0, len(utt)/sr, len(utt))\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "ax[0].plot(t, utt_f0, label='f0')\n",
    "librosa.display.waveshow(utt, sr=sr, axis='time', ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b416b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0ae296e0e08c4e09fb8b3ebba43bdbe",
     "grade": false,
     "grade_id": "cell-fc85371c00544fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## T9: Write a function to compute interpolate RMS values \n",
    "\n",
    "\n",
    "The root mean square (RMS) of a sequence of $N$ values is the square root of the arithmetic mean of the squares of the values, that is\n",
    "$$\n",
    "x_{RMS}=\\sqrt{ \\frac{1}{N} \\sum_{n=0}^{N-1}\\left[x(n)\\right]^{2}}\n",
    "$$\n",
    "\n",
    "The value $(x_{RMS})^{2}$ is the _power_ of a signal, that is, its _energy_ over a period time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11361525",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0effb5069a6121e995ebfb930308dbc0",
     "grade": false,
     "grade_id": "T9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sig_rms(x, frame_length, hop_length):\n",
    "    \"\"\"Computes and interpolates RMS values for every sample of a given signal x\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    return rmsi[0:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b72952",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efd24a5a93b4f009213acde0f43e4b33",
     "grade": true,
     "grade_id": "T9t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert np.isclose(np.sum(sig_rms(np.ones(3), 2, 1)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b39adb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81969eb327a87d099fc1da1440728d3b",
     "grade": false,
     "grade_id": "cell-e1099a95baca36ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Visualize the interpolated RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10465efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 1024\n",
    "hop = 256\n",
    "utt_rms = sig_rms(utt, fsize, hop)\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "ax[0].plot(t, utt_rms, label='RMS')\n",
    "librosa.display.waveshow(utt, sr=sr, axis='time', ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22ddf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66e31a44349680589ec470d6087da7c8",
     "grade": false,
     "grade_id": "cell-393d844e5e5d143f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Formant synthesizer\n",
    "\n",
    "The resonances of the vocal tract, known as formants, can be accurately approximated as second order resonant filters. These formants are created by the shaping of the vocal tract, which acts as a series of resonant cavities. Each of these cavities has a resonant frequency, which determines the frequency at which it will naturally vibrate.\n",
    "\n",
    "By using second order resonant filters to model these formants, the formant synthesizer can simulate the acoustic characteristics of the vocal tract, allowing it to produce vowel sounds and other vocal sounds.\n",
    "\n",
    "In this example we will model the vocal tract with a cascade of two second order resonant filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf1473",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4b1d2afb320d977ad32f47688971b1c",
     "grade": false,
     "grade_id": "cell-9619628eadba1f27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Second-order discrete-time system\n",
    "\n",
    "\n",
    "A second-order discrete-time system has the following transfer function\n",
    "$$\n",
    "H(z) = \\frac{K}{1-a_1 z^{-1} - a_2 z^{-2}}\n",
    "$$\n",
    "where $K$ is the static gain.\n",
    "\n",
    "The transfer function that can be written in terms of its poles:\n",
    "$$\n",
    "H(z) = K \\frac{(1-z_1 z^{-1})(1-z_2 z^{-1})}{(1-p_1 z^{-1})(1-p_2 z^{-1})}\n",
    "$$\n",
    "\n",
    "where $p_1$ and $p_2$ are the complex roots of the denominator of $H(z)$ known as poles.\n",
    "\n",
    "If $K=1$, the system can be implemented as\n",
    "$$\n",
    "y(n) = x(n) + a_1 y(n-1) + a_2 y(n-2)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align}\n",
    "a_1 &= p_1 + p_2\\\\\n",
    "a_2 &= - p_1 p_2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For this system to work as a resonator the poles must be complex conjugates of each other, that is, $p_1 = p_2^{\\ast}$. In this case:\n",
    "$$\n",
    "\\begin{align}\n",
    "a_1 &= 2\\Re{p_1}\\\\\n",
    "a_2 &= - |p_1|^2\n",
    "\\end{align}\n",
    "$$\n",
    "A resonator is characterized by its natural frequency $\\omega_n$ and damping ratio $zeta$. When $0<\\zeta<1$ the system is underdamped and the poles are complex conjugates. \n",
    "\n",
    "When modeling the vocal tract each formant is defined by a frequency and a bandwidth,\n",
    "\n",
    "The formant frequency is usually considered the undamped resonant frequency (or natural frequency):\n",
    "$$\n",
    "F = 2 \\pi \\omega_n\n",
    "$$\n",
    "\n",
    "The bandwidth is measured between the cutoff frequencies, most frequently defined as the frequencies at which the frequency response has fallen to half the value at its peak.\n",
    "$$\n",
    "B = f_{c_2} - f_{c_1} = \\frac{\\omega_n \\zeta}{\\pi}\n",
    "$$\n",
    "\n",
    "These continuous-time frequency values can be used to define the position of the poles of the continuous time transfer function:\n",
    "$$\n",
    "\\omega_{peak} = \\omega_n \\sqrt{1-2\\zeta^2}\n",
    "$$\n",
    "\n",
    "To find the corresponding discrete-time transfer function we need to map the poles into the z-plane:\n",
    "$$\n",
    "\\begin{align}\n",
    "p_1 &= e^{s_1 T}=e^{(-\\zeta \\omega_n + \\omega_n \\sqrt{\\zeta^2 -1})T}\\\\\n",
    "p_2 &= e^{s_2 T}=e^{(-\\zeta \\omega_n - \\omega_n \\sqrt{\\zeta^2 -1})T}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547a00a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0146474f80d7da496f9b3d17383c031",
     "grade": false,
     "grade_id": "cell-b3b98482ef270caf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def formant_filter_coeffs(F, B, sr):\n",
    "    T = 1/sr\n",
    "    wn = 2*np.pi*F\n",
    "    zeta = 2*np.pi*B/(2*wn)\n",
    "    s1 = -zeta*wn + 1j*wn*np.sqrt(1-zeta**2)\n",
    "    s2 = -zeta*wn - 1j*wn*np.sqrt(1-zeta**2)\n",
    "    p1 = np.exp(s1*T)\n",
    "    p2 = np.exp(s2*T)\n",
    "    a = np.poly([p1, p2])\n",
    "    b = np.array([np.sum(a)])\n",
    "    return b, a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feeded7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cc35e8177c1e0e9c47800d4db0af920",
     "grade": false,
     "grade_id": "cell-98b1a3e7cca39904",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Formant filter frequency response\n",
    "\n",
    "The function scypi.signal.freqz() can be used to get the samples of the frequency response of a system with a rational transfer function such as the formant filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsyn_sr = 8000\n",
    "F1 = 500\n",
    "B1 = 100\n",
    "\n",
    "b, a = formant_filter_coeffs(F1, B1, fsyn_sr)\n",
    "w, h = sig.freqz(b, a, worN=1024)\n",
    "f = w/(2*np.pi)*fsyn_sr\n",
    "plt.plot(f, 20*np.log10(abs(h)))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9cdc4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81ec1f94b89d73ac692e513f2f881bd6",
     "grade": false,
     "grade_id": "cell-a600b7fcc3f2a8cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cascading of two formant filters\n",
    "\n",
    "Connecting the output of one formant filter to another results in the product of the transfer function of both filters\n",
    "$$\n",
    "H(z) = \\frac{1}{1-a_{11} z^{-1} - a_{12} z^{-2}} \\frac{1}{1-a_{11} z^{-1} - a_{22} z^{-2}}\n",
    "$$\n",
    "The resulting filter coefficients are the convolution of the filter parameters\n",
    "$$\n",
    "H(z) = \\frac{1}{1 - \n",
    "(a_{11}+a_{12}) z^{-1} - \n",
    "(a_{12}-a_{11}a_{21}+a_{22}) z^{-2} -\n",
    "(-a_{11}a_{22}-a_{12}a_{21}) z^{-3} -\n",
    "(-a_{12}a_{22})z^{-4}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa51b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "F2 = 1500\n",
    "B2 = 100\n",
    "b1, a1 = formant_filter_coeffs(F1, B1, fsyn_sr)\n",
    "b2, a2 = formant_filter_coeffs(F2, B2, fsyn_sr)\n",
    "b = np.convolve(b1, b2)\n",
    "a = np.convolve(a1, a2)\n",
    "w, h = sig.freqz(b, a, worN=1024)\n",
    "f = w/(2*np.pi)*fsyn_sr\n",
    "plt.plot(f, 20*np.log10(abs(h)))\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9481517",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b453c725c918b8c8cdcd1ac8cc413a9b",
     "grade": false,
     "grade_id": "cell-1e9ad9d070503cbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T10: Write a function to generate the source signal\n",
    "\n",
    "For voiced sounds ($f_0>0$) the source signal is a train of impulses:\n",
    "$$\n",
    "e(n) = \\sqrt{P} \\sum_{k=-\\infty}^{+\\infty} \\delta(n-kP)\n",
    "$$\n",
    "where $P=1/f_0$ is the fundamental period, and $\\delta(n)$ is the unit impulse.\n",
    "\n",
    "For unvoiced sounds ($f_0=0$) the source signal is zero-mean unit-variance Gaussian white noise:\n",
    "$$\n",
    "e(n) \\sim \\mathcal{N} (0,1)\n",
    "$$\n",
    "\n",
    "Write a function that takes a f0 vector generated by the function sig_f0() and returns a vector with the same lenght with pulses or noise depending on the f0 estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23589b31",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63d460cafba1fefaabd650129245c041",
     "grade": false,
     "grade_id": "T10",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def source_generator(f0, sr):\n",
    "    \"\"\"Generates a periodic pulse train with given fundamental frequency or with random noise if f0=0\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    return exc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892d96e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30420c25a2b91d4ca27ac578e731a348",
     "grade": true,
     "grade_id": "T10t",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(source_generator(np.ones(64), sr)) == 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b6bd8",
   "metadata": {},
   "source": [
    "### T11: Synthesize a vowel\n",
    "\n",
    "In the following code block generate an audio signal `syn_vowel` with samples of a synthesized vowel with the following characteristics\n",
    "\n",
    "- Sample rate: 16000 Hz\n",
    "- Formant frequencies: F1 = 290 Hz, F2 = 680 Hz\n",
    "- Formant bandwidths: B1 = 50 Hz, B2 = 60 Hz\n",
    "- Duration: 0.6 s\n",
    "- Linearly decaying f0 from 250 Hz to 190 Hz\n",
    "- Raised cosine RMS: starts and ends in zero and maximum amplitude at the middle of the vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418be4cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95a7c0ce442f9302934a28804c3e8a7f",
     "grade": false,
     "grade_id": "cell-103220b4df7d570a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fsyn_sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac59f61",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e3b3e0521ec0bb979f986f4af3ddfff",
     "grade": true,
     "grade_id": "T11",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae86587",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90d64e13062820db26875dc6d728aae4",
     "grade": false,
     "grade_id": "cell-c3627f7d0639802d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T12: Identify the vowel\n",
    "\n",
    "In the next text box identify the vowel that was synthesize, what parameters where more relevant for that result and the effects produced by the other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40177887",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdd582d44866e77a651b36ea384cea50",
     "grade": true,
     "grade_id": "T12",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4573a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0ee9ff3073cb58cdb9e9ad5b72220e4",
     "grade": false,
     "grade_id": "cell-56469e77d43176b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## LPC Vocoder\n",
    "\n",
    "An LPC (Linear Predictive Coding) vocoder combines the LPC analysis and LPC synthesis.\n",
    "\n",
    "We saw that in LPC analysis, the speech signal is modeled as a linear combination of past samples, and the model coefficients are a good estimation the signal's spectral envelope.\n",
    "\n",
    "In the source-filter model, the vocal tract is responsible for speech signal's spectral envelope. If we assume that the vocal tract is an all-pole filter, the LPC coefficients can be used as the parameters for that filter.\n",
    "\n",
    "Since the vocal tract changes in time, we need a filter that can also change in time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40ca40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b45d9f3c5ac11d03932df9ba37426d98",
     "grade": false,
     "grade_id": "cell-527080b4698d6ebd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Time varying overlap-add filter\n",
    "\n",
    "Using the same approach that we used for analysing non-stationary signals, we can split the filtering process using a frame-by-frame approach.\n",
    "\n",
    "The only difference is that we need to make sure that the signal framing process does not modify the amplitude of the reconstructed signal. This can be achieved, for example, by using\n",
    "Hanning windows and an hop value equal to half of the frame length. This way, the sum of all windows equals one except in the first half of the first frame and in the last half of the last frame.\n",
    "\n",
    "This process is called overlap-add filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58227f0a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e59aefcd9384005df7629eade46cb04",
     "grade": false,
     "grade_id": "cell-d8609976869cecac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def variable_filter(b, a, x, frame_length=1024, hop_length=512):\n",
    "    \"\"\"Frame-based filtering with time-varying filter coefficients\"\"\"\n",
    "    N = len(x)\n",
    "    w = np.hanning(frame_length)\n",
    "    x_pad = pad_signal(x, hop_length, hop_length)\n",
    "    x_frames = librosa.util.frame(x_pad, frame_length=frame_length, hop_length=hop_length, axis=0)\n",
    "    y_frames = np.zeros(x_frames.shape)\n",
    "    min_frames = min(b.shape[0], a.shape[0], x_frames.shape[0])\n",
    "    for f in range(min_frames):\n",
    "        y_frames[f] = sig.lfilter(b[f], a[f], x_frames[f])\n",
    "    # overlap_add\n",
    "    y = np.zeros_like(x_pad)\n",
    "    for n in range(0, len(x_pad) - frame_length, hop_length):\n",
    "        y[n:n+frame_length] += y_frames[n//hop_length] * w\n",
    "    return y[:N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928851c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f00cd655c897427098bd26894f4b20b2",
     "grade": false,
     "grade_id": "cell-82c4900238f1d82f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Test of the overlap-add filter\n",
    "\n",
    "To test the time-varying filter we will use a fixed low pass filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461dbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th order Butterworth lowpass filter\n",
    "fc = 3000\n",
    "butter_b, butter_a = sig.butter(4, fc/sr, 'low')\n",
    "\n",
    "# Number of frames\n",
    "frame_length = 1024\n",
    "hop_length = frame_length//2\n",
    "nframes = len(utt)//hop_length + (len(utt)%hop_length >0)\n",
    "\n",
    "# time-varying filter coefficients\n",
    "b = np.tile(butter_b, (nframes, 1))\n",
    "a = np.tile(butter_a, (nframes, 1))\n",
    "\n",
    "# apply filter\n",
    "utt_lowp = variable_filter(b, a, utt, frame_length, hop_length)\n",
    "librosa.display.waveshow(utt_lowp, sr=sr)\n",
    "display(Audio(utt, rate=sr))\n",
    "display(Audio(utt_lowp, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449801ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c5d33bd2a5f2622d0661dd04e97e45f",
     "grade": false,
     "grade_id": "cell-70d131c05b9d78a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T13: Frame-based LPC analysis\n",
    "\n",
    "To generate the parameters of the LPC filter we need to perform an LPC analysis for every frame of the signal.\n",
    "Use a Hanning window together with the lpc() function defined previously to compute the LPC parameters for each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352972ab",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e55f879b204d3354b6d3256e7575a24",
     "grade": false,
     "grade_id": "T13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def frame_based_lpc(x, order, frame_length, hop_length):\n",
    "    \"\"\"Computes frame-base LPC parameters of signal x\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    return lpc_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf83b4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "698b430036b4d1fb01ddcd3fecf9ef8b",
     "grade": true,
     "grade_id": "T13t",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (frame_based_lpc(np.sin(2*np.pi*np.arange(200)/20),10,100,50).shape[0] == 4)\n",
    "assert (frame_based_lpc(np.sin(2*np.pi*np.arange(200)/20),10,100,50).shape[1] == 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6120e",
   "metadata": {},
   "source": [
    "#### Test of the frame-based LPC analysis\n",
    "\n",
    "A good way to test the LPC analysis is by estimating the LPC error or residual signal that can be obtained by filtering the original signal with an all-zeros filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b94d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 20\n",
    "frame_length = 2048\n",
    "hop_length = frame_length//2\n",
    "lpc_coeffs = frame_based_lpc(utt, order, frame_length, hop_length)\n",
    "a = np.tile(1, (len(lpc_coeffs), 1))\n",
    "\n",
    "utt_resid = variable_filter(lpc_coeffs, a, utt, frame_length, hop_length)\n",
    "librosa.display.waveshow(utt_resid, sr=sr)\n",
    "display(Audio(utt_resid, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b40f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e17e2d2a821a70c3bfd93bed354d21cb",
     "grade": false,
     "grade_id": "cell-7ce887687e9b1a74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T14: Residual signal\n",
    "\n",
    "By listening to the residual signal what can you conclude about the capacity of this LPC filter to model the vocal tract? What features may the model be missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10b36f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e51f11d07eb0a15e516c128b51ff920a",
     "grade": true,
     "grade_id": "T14",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa3f66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a20497ddfd92a284fbc67845bd61d941",
     "grade": false,
     "grade_id": "cell-60c0227736845f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### T15: LPC synthesis\n",
    "\n",
    "You now have all the tools to generate a synthetic version of the residue signal that can be used at the input of the all-poles LPC filter to synthesize a version of the original file.\n",
    "\n",
    "In the next code cell generate a synthetic version of the first Harvard sentence based on the LPC parameters, F0 and RMS estimation.\n",
    "\n",
    "Use a downsampled version of `utt` to see the effect of the original signal bandwith in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sr = 16000\n",
    "utt_rs = librosa.resample(utt, orig_sr=sr, target_sr=new_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c9050",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e58eb38c2397473d132b26ede6a9d1d",
     "grade": true,
     "grade_id": "T15",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2077ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5169a2fed0ae8ac2a0f468230c943d6",
     "grade": false,
     "grade_id": "cell-8305d4f4c706eb94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "display(Audio(utt_exc, rate=new_sr))\n",
    "display(Audio(utt_syn, rate=new_sr))\n",
    "librosa.display.waveshow(utt_syn, sr=new_sr)\n",
    "display(Audio(utt_syn, rate=new_sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e7ed7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d85d31fd1ea8783f2c7277bdd5161134",
     "grade": false,
     "grade_id": "1234",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T16: Robotic voice\n",
    "\n",
    "Modify the previous code to generate an all voice signal with fixed fundamental frequency of $f_0 = 180 Hz$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971a093",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50c43a4a651d7fe751754ac9d487e54e",
     "grade": true,
     "grade_id": "T16",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a49640",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd1390c6f50b1320ae7955d39bde8fdc",
     "grade": false,
     "grade_id": "cell-7041363c6940b3e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### T17: whispered voice\n",
    "\n",
    "Modify the previous code to generate a fully unvoice signal that simulates a whispered voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d611e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3df44d36bcf068639855edf40225850",
     "grade": true,
     "grade_id": "T17",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "49345cbd358e70c3061d915ca81696aa8f7e07e483518f8ab6512698c1722880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
